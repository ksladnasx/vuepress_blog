---
date: 2025-12-15
category:
  - 期末复习
tag:
  - 操作系统
---



# 操作系统期末复习文档

## 第一章 概述

### 1. 操作系统的基本概念、特点、基本功能

- **基本概念**：操作系统是一组控制和管理计算机软硬件资源、合理组织计算机工作流程、方便用户使用的程序集合。它既是 “扩展的机器”（隐藏硬件细节，提供友好接口），也是 “资源管理器”（实现多道程序、多用户的资源调度与分配）。

- **核心特点**：并发性（多个事件同一时间间隔内发生）、共享性（资源被多个进程共同使用）、虚拟性（通过技术将物理资源抽象为多个逻辑资源）、异步性（进程按不可预知的速度推进，但结果可再现）。

- 基本功能

  ：

  - 处理机管理：进程控制、同步、通信及处理机调度。
  - 存储器管理：内存分配、保护、地址映射及内存扩充。
  - 设备管理：缓冲管理、设备分配及设备驱动程序处理。
  - 文件管理：外存管理、目录管理、文件读写与保护。
  - 用户接口：提供程序接口（系统调用）、命令接口、图形接口。
  - 作业管理：作业组织与调度。

### 2. 分时系统、批处理系统、实时系统的主要特征

- **分时系统**：交互性（用户与系统实时交互）、多路性（多个用户共享 CPU）、独立性（用户互不干扰）、及时性（短时间内响应用户请求）。
- **批处理系统**：脱机使用（无实时交互）、成批处理（作业批量提交）、多道批处理具有高资源利用率和大吞吐量，但作业周转时间长。
- **实时系统**：事件驱动（响应外部实时事件）、及时性（严格满足时间约束）、高可靠性（保障关键任务正确执行），兼具独立性、交互性和多路性。

### 3. 用户接口类型、系统调用过程

- 用户接口类型

  ：

  - 命令接口：通过命令控制计算机，包括 shell 命令（如 ls、mkdir）和 shell 编程（支持循环、条件判断等）。
  - 程序接口（系统调用）：用户程序通过调用系统函数获取 OS 服务，如文件操作、进程控制相关调用。
  - 图形接口：可视化操作界面，直观便捷。

- 系统调用过程

  ：

  1. 用户程序调用库函数（如 read），库函数将系统调用参数存入指定寄存器。
  2. 执行陷阱指令（trap），切换 CPU 模式从用户态到内核态。
  3. 内核中的系统调用处理程序接收请求，根据调用号查找对应的服务程序。
  4. 执行服务程序，完成资源操作或功能实现。
  5. 将结果返回给库函数，再由库函数返回给用户程序，同时切换回用户态。

### 4. 多道程序技术

- 定义：批处理系统中，每次调入多个作业进入内存并并发运行（单 CPU 环境下宏观并行、微观串行）。
- 核心作用：提高 CPU 利用率、提升系统吞吐量，缓解 CPU 与 I/O 设备速度不匹配的问题。
- 关键问题：需解决进程同步、互斥、资源分配等问题，避免冲突。

### 5. 常用系统调用及作用

- **文件操作类**：creat（创建文件）、open（打开文件）、close（关闭文件）、read（读文件）、write（写文件）、unlink（删除文件），用于文件的创建、访问与管理。
- **进程控制类**：fork（创建子进程）、wait（等待子进程结束）、exit（进程退出）、getpid（获取进程 ID）、kill（发送信号给进程），用于进程的创建、控制与通信。
- **作用**：为用户程序提供访问系统资源的合法接口，隔离用户态与内核态，保障系统安全与稳定。

### 6. 操作系统的体系结构

- **单一内核体系结构**：所有功能模块（如进程管理、内存管理）集中在核心内核中，结构简单、效率高，但可维护性差。
- **分层体系结构**：按功能分层（如 0 层为处理器分配、1 层为内存管理、3 层为 I/O 管理），层间单向依赖，降低耦合度，便于维护。
- **微内核体系结构**：内核仅保留最基本功能（如进程通信、地址映射），其他功能由用户态的服务器进程实现，灵活性高、可靠性强，但通信开销大。
- **虚拟机体系结构**：通过虚拟机管理程序（VMM）将物理硬件抽象为多个虚拟机器，多个操作系统可同时运行，隔离性好。

### 7. CPU 工作模式、系统启动引导的基本流程

- CPU 工作模式

  ：

  - 内核态（核心态）：CPU 可执行所有指令，访问所有硬件资源，OS 核心程序在此模式运行。
  - 用户态：仅允许执行指令集子集，访问有限资源，用户程序在此模式运行，需通过系统调用切换到内核态访问核心资源。

- 系统启动引导流程

  ：

  1. 加电自检（POST）：检查硬件设备是否正常。
  2. 加载 BIOS：初始化硬件，建立中断向量表和中断服务程序，进入 16 位实模式（绝对地址寻址，无分页机制）。
  3. 加载引导程序：BIOS 从启动设备读取引导程序（如 GRUB），由引导程序加载 OS 内核。
  4. 切换到保护模式：启用分段、分页机制，建立 GDT/LDT，支持 32 位 / 64 位寻址。
  5. 内核初始化：初始化数据结构、设备驱动，安装根文件系统。
  6. 创建 init 进程（1 号进程）：生成各终端进程，启动 shell，系统进入可用状态。

## 第二章 进程与线程

### 1. 进程的基本概念、进程的顺序执行与并发执行特点

- **基本概念**：进程是程序的一次执行过程，是系统资源分配的基本单位，包含程序、数据集和进程控制块（PCB）三部分。
- **顺序执行特点**：顺序性（按指令顺序执行）、封闭性（初始条件确定则结果唯一）、可再现性（与执行速度无关）。
- **并发执行特点**：独立性（多个进程逻辑独立）、随机性（运行时机不确定）、资源共享性（竞争或协作使用资源），失去封闭性和可再现性。

### 2. 线程的基本概念

- 定义：线程是轻量级进程，是进程内的基本调度单位，拥有自己的程序计数器、寄存器和堆栈，但共享所属进程的地址空间、打开文件、全局变量等资源。
- 核心特征：调度开销小（无需切换地址空间）、并发度高（同一进程内多个线程可并发执行）、资源共享（简化进程间通信）。

### 3. 进程与程序、进程与线程的区别与联系

- 进程与程序的区别：

  - 进程是动态的（执行过程），程序是静态的（指令集合）。
  - 进程可并发执行，程序不可直接并发。
  - **进程是资源分配的基本单位**，程序不占用资源。
  
- **进程与程序的联系**：一个程序可对应多个进程（如多个终端运行同一 shell 程序），一个进程可包含多个程序（如进程执行时调用多个库程序）。

- 进程与线程的区别：

  - 资源分配：进程是资源分配基本单位，线程不独立分配资源。
  - 调度：线程是资源调度基本单位，进程是调度的间接单位。
  - 开销：进程创建、切换开销大，线程开销小。
  - 独立性：进程独立性强（崩溃不影响其他进程），线程独立性弱（同一进程内线程崩溃可能导致进程退出）。
  
- **进程与线程的联系**：线程是进程的组成部分，一个进程至少包含一个线程（主线程），线程不能脱离进程独立存在。

### 4. 进程的实现、线程的实现

- 进程的实现

  ：

  - 核心数据结构：PCB（进程控制块），是标识进程存在的唯一实体，包含描述信息（进程 ID、用户名）、控制信息（状态、优先级）、资源管理信息（内存地址、设备占用）、CPU 现场保护信息（寄存器值）。
  - 实现方式：通过创建原语（分配 PCB、初始化信息、加入就绪队列）、撤销原语（释放资源、删除 PCB）等完成进程生命周期管理。

- 线程的实现

  ：

  - 用户级线程：在用户态实现，由线程库管理，内核不感知，切换无需内核态切换，开销小，但无法利用多 CPU。
  - 内核级线程：在内核态实现，由内核管理，内核为每个线程分配 TCB（线程控制块），可利用多 CPU，但切换开销大。
  - 混合实现：用户级线程与内核级线程映射（如多对一、一对一、多对多），兼顾开销与并行性。

### 5. 进程的基本状态及其转换

- 基本状态

  ：

  - 运行态（Running）：进程正在使用 CPU 执行指令。
  - 就绪态（Ready）：进程已获取除 CPU 外的所有资源，等待调度。
  - 阻塞态（Blocked）：进程因等待某事件（如 I/O 完成、资源申请失败）而暂停执行，需事件触发唤醒。

- 状态转换

  ：

  1. 就绪态→运行态：进程调度器选中就绪队列中的进程，分配 CPU。
  2. 运行态→就绪态：时间片用完或有更高优先级进程进入就绪队列。
  3. 运行态→阻塞态：进程请求 I/O 或申请资源失败。
  4. 阻塞态→就绪态：等待的事件发生（如 I/O 完成、资源可用），由唤醒原语触发。

### 6. 临界资源、临界区、进程的同步与互斥概念；信号量实现

- 核心概念

  ：

  - 临界资源：一次只允许一个进程使用的资源（如打印机、共享内存）。
  - 临界区：进程中访问临界资源的代码段。
  - 进程互斥：多个进程竞争临界资源时，仅允许一个进程进入临界区，其他进程等待。
  - 进程同步：多个并发进程因协作需要，按一定顺序执行（如生产者 - 消费者问题中，生产者先生产，消费者后消费）。

- 信号量实现

  ：

  - 信号量（semaphore）：是与队列相关的整型变量，仅通过 P（down）、V（up）原语操作，用于描述资源数量或同步状态。
  - 互斥实现：设互斥信号量 mutex=1，进程进入临界区前执行 P (mutex)（申请资源），退出时执行 V (mutex)（释放资源），确保同一时间仅一个进程进入临界区。
  - 同步实现：设同步信号量 s=0（表示等待事件未发生），等待进程执行 P (s)（阻塞等待），触发事件的进程执行 V (s)（唤醒等待进程）。

### 7. 作业的状态、常见的作业及进程调度算法

- 作业的状态：

  - 后备态：作业提交后，等待进入内存。
  - 运行态：作业进入内存，对应的进程正在执行或就绪。
  - 完成态：作业执行完毕，释放资源。
  
- 作业调度算法：

  - 先来先服务（FCFS）：按作业提交顺序调度，公平但对短作业不友好。
  - 最短作业优先（SJF）：选择执行时间最短的作业，吞吐量高但长作业可能饥饿。
  - 响应比高优先（HRN）：响应比 =（等待时间 + 执行时间）/ 执行时间，兼顾短作业和长作业。
  
- 进程调度算法：

  - 先来先服务（FCFS）：按就绪顺序调度，简单但调度效率低。
  - 最短剩余时间优先（SRTF）：可剥夺式 SJF，选择剩余执行时间最短的进程，吞吐量高。
  - 轮转法（RR）：按时间片分配 CPU，每个进程轮流使用，适用于分时系统，响应及时。
  - 优先级调度：选择优先级高的进程，分为静态优先级（创建时确定）和动态优先级（运行中调整），可能导致低优先级进程饥饿。
  - 多级反馈队列调度：多个优先级队列，进程按优先级进入对应队列，高优先级队列时间片短，低优先级队列时间片长，兼顾响应时间和吞吐量。

## 第三章 死锁

### 1. 死锁的概念

死锁是指两个或多个进程相互等待对方占有的资源，导致所有进程都无法继续执行的僵死状态。此时每个进程都在等待只能由该集合中其他进程释放的资源，无法主动退出。

### 2. 死锁产生的原因及必要条件

- **产生原因**：资源竞争（多个进程争夺有限的不可抢占资源）、进程推进顺序不当（进程申请资源的顺序与资源分配顺序冲突）。

- 必要条件

  （缺一不可）：

  1. 互斥条件：资源要么分配给一个进程，要么可用，不可共享。
  2. 占有和等待条件：进程已占有部分资源，同时申请新的资源。
  3. 不可抢占条件：已分配的资源不能被强制剥夺，只能由进程主动释放。
  4. 环路等待条件：存在由多个进程组成的环路，每个进程都在等待下一个进程占有的资源。

### 3. 死锁问题的解决策略

- 死锁预防

  ：破坏死锁的一个或多个必要条件，如：

  - 破坏互斥条件：采用假脱机技术（如打印机），将独占资源转化为共享资源。
  - 破坏占有和等待条件：进程启动前申请所有所需资源，或释放已占有资源后再申请新资源。
  - 破坏不可抢占条件：对可抢占资源（如内存），允许内核强制剥夺。
  - 破坏环路等待条件：对资源编号，进程按编号顺序申请资源。

- **死锁避免**：动态检测资源分配状态，确保系统始终处于安全状态，避免死锁发生（如银行家算法）。

- **死锁检测与恢复**：允许死锁发生，定期检测死锁，检测到后通过抢占资源、回滚进程、终止进程等方式恢复系统。

- **鸵鸟算法**：忽略死锁问题，适用于死锁发生概率极低的场景，节省系统开销。

### 4. 安全状态的定义、银行家算法

- **安全状态定义**：如果系统存在一种调度顺序，使得所有进程都能按此顺序执行完毕（即每个进程都能获得所需资源并释放），则称系统处于安全状态。安全状态无死锁，不安全状态可能导致死锁。

- 银行家算法

  ：

  - 核心思想：模拟资源分配，仅当分配资源后系统仍处于安全状态时，才允许分配。
  - 关键数据结构：
    - 可用资源向量（Available）：当前可用的各类资源数量。
    - 分配矩阵（Allocation）：每个进程已分配的各类资源数量。
    - 需求矩阵（Need）：每个进程还需要的各类资源数量（Need=Max-Allocation，Max 为进程最大资源需求）。
  - 算法步骤：
    1. 检查请求资源的进程的需求是否超过其最大需求，若超过则拒绝。
    2. 检查可用资源是否满足进程的请求，若不满足则进程阻塞。
    3. 模拟分配资源，更新 Available、Allocation、Need 矩阵。
    4. 检查更新后的系统是否处于安全状态（即存在安全序列），若安全则确认分配，否则撤销模拟分配，进程阻塞。
  - 安全序列：是指进程的一个执行顺序，使得每个进程在序列中都能获得所需资源并完成执行，释放资源供后续进程使用。

## 第四章 存储管理

### 1. 分页存储管理方式原理

- 核心思想：将用户进程的虚拟地址空间划分为大小固定的页（Page），将物理内存划分为与页大小相同的块（Block / 页框）。
- 地址映射：通过页表实现虚拟地址到物理地址的转换。虚拟地址分为页号和页内偏移，页号作为页表索引，查找页表得到对应的页框号，页框号与页内偏移拼接得到物理地址。
- 关键组件：
  - 页表：每个进程一张页表，记录页与页框的映射关系，包含页框号、“在 / 不在” 位（是否在内存）、修改位、访问位等。
  - 内存管理单元（MMU）：硬件组件，负责地址映射和页表查找。

### 2. 覆盖技术、交换技术

- **覆盖技术**：将程序划分为常驻内存的核心部分和可替换的覆盖部分，当需要执行某功能时，将对应的覆盖部分装入内存，覆盖其他暂时不用的覆盖部分，适用于内存较小的场景，需程序员手动划分模块。
- **交换技术**：当内存不足时，将内存中暂时不用的进程（或部分）换出到外存（交换区），释放内存空间供其他进程使用；当进程需要继续执行时，再将其换入内存。分为整体交换（换出整个进程）和页面交换（虚拟存储中的页面置换）。

### 3. 物理内存管理方式

- 连续存储管理：

  - 单一分区：内存分为操作系统区和用户区，仅允许一个用户进程运行，简单但资源利用率低。
  - 固定多分区：内存划分为多个固定大小的分区，每个分区可运行一个进程，分区大小固定，灵活性差，存在内部碎片。
  - 可变分区：根据进程需求动态划分内存分区，无内部碎片，但存在外部碎片，需通过紧凑技术整理。
  
- 离散存储管理：

  - 分页存储：按固定大小划分，无外部碎片，有少量内部碎片。
  - 分段存储：按逻辑结构划分（如代码段、数据段），段大小可变，无内部碎片，有外部碎片。
  - 段页式存储：先分段，再将每段分页，结合分页和分段的优点，地址映射需经过段表和页表两级查找。

### 4. 可变分区存储管理方式原理及动态分区管理常用内存分配算法

- **原理**：内存不预先划分分区，当进程申请内存时，根据进程大小动态划分一个连续的分区分配给进程；进程结束时，释放分区并与相邻空闲分区合并。

- 常用分配算法

  ：

  - 首次适配算法（First Fit）：从内存起始位置查找，找到第一个能满足需求的空闲分区分配，简单高效，但容易产生小的外部碎片。
  - 下次适配算法（Next Fit）：从上次分配的位置继续查找，避免重复查找前面的小碎片，但可能导致内存尾部碎片积累。
  - 最佳适配算法（Best Fit）：查找所有空闲分区，选择大小最接近需求的分区分配，内部碎片最小，但查找开销大，可能产生大量小碎片。
  - 最差适配算法（Worst Fit）：选择最大的空闲分区分配，避免小碎片积累，但可能破坏大分区，不利于大进程申请。

### 5. 页表及多级页表、TLB、页的大小

- **页表**：记录页与页框的映射关系，页表项包含页框号、“在 / 不在” 位、修改位、访问位、保护位等。单级页表适用于地址空间小的场景，地址空间大时（如 32 位、64 位）页表过大，占用大量内存。

- **多级页表**：将页表划分为多个级别的子页表，如二级页表（顶级页表 + 二级页表），虚拟地址分为页目录号、页表号、页内偏移，仅需加载当前使用的子页表，节省内存空间。

- **TLB（快表）**：高速缓冲存储器，存储近期访问的页表项，地址映射时先查 TLB，命中则直接得到页框号，未命中再查页表，减少内存访问次数，提高映射速度。

- 页的大小

  ：

  - 小页面：内部碎片少，灵活适配程序结构，但页表大，系统开销大。
  - 大页面：页表小，系统开销小，但内部碎片多，内存利用率低。
  - 最优页面大小：由公式\(p=\sqrt{2se}\)（s 为进程平均大小，e 为页表项大小）推导，平衡内部碎片和页表开销。

### 6. 常用页面置换算法及缺页率计算

- **缺页中断**：进程访问的页面不在内存时，触发缺页中断，需将页面从外存调入内存，若内存无空闲页框，需通过页面置换算法淘汰某页面。

- 常用页面置换算法

  ：

  1. 最优算法（OPT）：淘汰未来最长时间内不使用的页面，缺页率最低，但无法实现（需预知未来访问序列），仅作为基准。
  2. 先进先出算法（FIFO）：淘汰最早进入内存的页面，简单易实现，但可能出现 Belady 现象（页框数增加，缺页率反而上升）。
  3. 最近未使用算法（NRU）：根据页面的访问位和修改位将页面分为 4 类，淘汰分类编号最小的页面，是 LRU 的近似，开销小。
  4. 最近最少使用算法（LRU）：淘汰最近最少使用的页面，缺页率低，但需维护页面访问顺序（如链表或计数器），硬件支持要求高。
  5. 时钟算法（Clock）：页面按环形排列，用指针指向当前检查的页面，若页面访问位为 1 则置 0 并移动指针，若为 0 则淘汰该页面，开销小，接近 LRU 性能。

- **缺页率计算**：缺页率 = 缺页次数 / 总访问次数 ×100%。例：页面走向为 4,3,2,1,4,3,5,4,3,2,1,5，分配 3 个页框，OPT 缺页次数 7 次，缺页率 7/12≈58.3%；FIFO 缺页次数 9 次，缺页率 75%；LRU 缺页次数 10 次，缺页率≈83.3%。

### 7. 段式存储原理、段式与页式存储的主要区别

- 段式存储原理

  ：

  - 将用户进程的虚拟地址空间按逻辑结构（如代码段、数据段、堆栈段）划分为多个段，每个段有独立的段名和段内地址（从 0 开始）。
  - 地址结构：段号 + 段内偏移，通过段表实现地址映射，段表记录段的物理始址、段长、访问权限等。
  - 核心特点：段长可变，便于程序模块化设计和共享，支持段的动态增长。

- 段式与页式存储的主要区别

  ：

  | 对比项     | 页式存储                     | 段式存储                       |
  | ---------- | ---------------------------- | ------------------------------ |
  | 划分依据   | 物理单位（固定大小）         | 逻辑单位（可变大小）           |
  | 地址空间   | 一维（页号 + 页内偏移）      | 二维（段号 + 段内偏移）        |
  | 碎片类型   | 内部碎片                     | 外部碎片                       |
  | 共享与保护 | 困难（按页共享，无逻辑意义） | 容易（按段共享，符合逻辑结构） |
  | 动态增长   | 不支持                       | 支持（段可动态扩展）           |
  | 程序员感知 | 无需感知（系统自动划分）     | 需感知（程序按段组织）         |

## 第五章 文件系统

### 1. 文件的逻辑结构、物理结构、文件 FCB

- 文件的逻辑结构

  ：

  - 无结构文件（流式文件）：文件是字节序列，如文本文件，适用于顺序存取。
  - 有结构文件：
    - 记录式文件：由多个逻辑记录组成（如数据库文件），支持顺序存取和随机存取。
    - 树型文件：文件内容按树结构组织，如目录文件。

- 文件的物理结构

  ：

  - 连续结构：文件数据连续存储在磁盘的连续块中，顺序存取速度快，但随机存取慢，文件扩展困难，易产生外部碎片。
  - 链表结构：文件数据存储在不连续的块中，块之间通过指针链接，文件扩展方便，无外部碎片，但随机存取慢，指针占用额外空间。
  - 索引结构：为文件建立索引块，索引块记录文件数据块的地址，文件数据块不连续，支持随机存取和文件扩展，索引块占用内存 / 磁盘空间。

- 文件 FCB（文件控制块）

  ：描述文件属性信息的数据结构，是文件的唯一标识，包含：

  - 基本信息：文件名、文件类型、文件大小。
  - 存取控制信息：所有者、访问权限（读 / 写 / 执行）。
  - 地址信息：文件物理地址（连续结构的始址和长度、链表结构的首块地址、索引结构的索引块地址）。
  - 管理信息：创建时间、修改时间、访问时间。

### 2. 文件的目录结构、文件路径、文件的共享方式

- 文件的目录结构

  ：

  - 一级目录结构：所有文件放在一个根目录中，简单但文件重名冲突，适用于单用户。
  - 二级目录结构：根目录下分用户目录，每个用户有独立的用户目录，解决重名问题，但不支持文件共享。
  - 层次目录结构（树型目录）：根目录下有子目录，子目录下可再包含文件和子目录，结构清晰，支持文件分类和共享，如 UNIX/Linux 的目录结构。

- 文件路径

  ：

  - 绝对路径：从根目录开始的完整路径（如 /usr/ast/mbox）。
  - 相对路径：从当前工作目录开始的路径（如 ast/mbox，当前目录为 /usr）。

- 文件的共享方式

  ：

  - 硬链接（共享索引节点）：多个目录项指向同一个 FCB（索引节点），共享文件数据和属性，删除一个目录项不影响其他，仅当所有链接删除后文件才被删除。
  - 软链接（符号链接）：创建一个新文件，文件内容是被链接文件的路径，访问时通过路径查找目标文件，目标文件删除后链接失效，类似于 Windows 的快捷方式。

### 3. 文件的磁盘空间管理方式

- **空闲块链表**：将所有空闲磁盘块链接成链表，分配时从链表头取块，释放时将块插入链表，简单但查找效率低，适用于小容量磁盘。
- **位图法**：用一位（bit）表示一个磁盘块的状态（0 为空闲，1 为占用），形成位图，分配时查找位图中的 0 位，释放时将对应位设为 0，查找效率高，占用空间小，适用于大容量磁盘。
- **空闲块成组链接法**：将空闲块分成若干组，每组的块数和下一组的起始地址记录在该组的最后一块中，兼顾链表法和位图法的优点，查找效率高，占用空间小，是 UNIX 系统采用的方式。

### 4. 文件系统的可靠性

- 文件备份

  ：

  - 全量备份：备份所有文件，恢复快但备份时间长、占用空间大。
  - 增量备份：仅备份上次备份后修改的文件，备份时间短、占用空间小，但恢复时需按备份顺序依次恢复。
  - 物理备份：直接复制磁盘块，速度快但无法恢复单个文件。
  - 逻辑备份：按文件逻辑结构备份，可恢复单个文件但速度慢。

- 文件一致性

  ：确保文件系统的元数据（目录、FCB、空闲块管理信息）和文件数据一致，避免因断电、崩溃等导致数据损坏。

  - 块一致性：检查磁盘块的分配状态（是否既在空闲块中又被文件占用，或既不在空闲块中也未被文件占用）。
  - 文件一致性：检查文件的块数、大小等信息与 FCB 中的记录一致。
  - 一致性检查工具：如 UNIX 的 fsck 命令，通过扫描磁盘修复不一致问题。

### 5. 文件系统的性能

- **高速缓存（Buffer Cache）**：将近期访问的磁盘块数据缓存到内存中，下次访问时直接从内存读取，减少磁盘 I/O 次数，提高访问速度。

- **块提前读**：顺序存取文件时，提前将后续磁盘块读入缓存，预判用户访问行为，减少等待时间。

- 减少磁盘臂运动

  ：

  - 优化文件块分配：将文件的连续块分配在同一柱面或相邻柱面，减少寻道时间。
  - 优化目录项排列：将常用目录项放在一起，减少目录查找时的磁盘臂移动。

- **磁盘碎片整理**：移动文件数据，将分散的文件块整理为连续块，减少寻道时间和旋转延迟，提高顺序存取速度。

### 6. 文件的存取访问过程

以 UNIX 系统为例，文件存取过程如下：

1. 用户通过路径名（如 /usr/ast/file.txt）访问文件，系统先查找根目录的 FCB，获取 /usr 目录的物理地址。
2. 访问 /usr 目录的磁盘块，查找 ast 子目录的 FCB，获取其物理地址。
3. 访问 ast 目录的磁盘块，查找 file.txt 的 FCB（索引节点），获取文件的物理地址（如索引块地址）。
4. 根据文件的物理结构，读取索引块（索引结构），获取文件数据块的地址。
5. 访问数据块，读取或写入文件数据。
6. 若开启高速缓存，数据会先经过缓存，减少磁盘 I/O。

## 第六章 设备管理

### 1. I/O 设备与系统的交互方式、I/O 统一编址与 I/O 独立编址

- **I/O 设备控制传输的方式：**

  - 程序控制 查询方式：CPU 不断查询设备状态，设备就绪后进行数据传输，CPU 忙等待，效率低，适用于简单设备（如 LED）。

    单次控制传输量：每次仅传输一字节或一个字，效率低。

    

  - 中断方式：CPU 发出 I/O 命令后继续执行其他程序，设备完成后向 CPU 发送中断信号，CPU 响应中断并处理数据传输，效率高，适用于大多数设备。

    单次控制传输量：每次仅传输一字节或一个字，但可配合DMA方式实现高效批量传输。

  

  - DMA方式：由 DMA 控制器直接控制设备与内存的数据传输，无需 CPU 干预，仅在传输开始和结束时通知 CPU，适用于高速设备（如磁盘、网卡）。

    单次控制传输量：可批量传输多个字节或字，通常为一个数据块。

    

  -  I/O通道控制方式：通道是专门负责 I/O 的处理器，CPU 向通道发送 I/O 命令，通道独立完成设备与内存的数据传输，支持多设备并行，适用于大型计算机或高并发系统。

    单次控制传输量：每次可传输大量数据甚至整个文件或数据流，依赖通道程序控制。

    

- **I/O 编址方式：**

  - I/O 独立编址（专用 I/O 端口）：为 I/O 设备分配独立的地址空间（I/O 端口），CPU 通过专用指令（如 IN、OUT）访问，地址空间与内存分离，不占用内存地址，但需专用指令和控制逻辑。
- I/O 统一编址（内存映射 I/O）：将 I/O 设备的控制寄存器和数据寄存器映射到内存地址空间，CPU 通过访问内存的指令（如 MOV）访问设备，无需专用指令，控制逻辑简单，但占用部分内存地址。

### 2. I/O 设备独立性

- 定义：应用程序独立于具体使用的物理设备，即程序使用逻辑设备名访问设备，由操作系统将逻辑设备名映射为物理设备名，实现 “设备无关性”。
- 核心作用：提高程序可移植性（更换设备无需修改程序）、简化设备管理（操作系统统一管理设备驱动）。
- 实现方式：操作系统提供设备独立性软件，维护逻辑设备表（LUT），记录逻辑设备名与物理设备名、设备驱动程序的映射关系。

### 3. 常用 I/O 数据传送方式

- 程序控制 I/O、中断驱动 I/O、DMA、通道控制方式（详细描述见本章第 1 点）。
- 对比：程序控制 I/O 简单但 CPU 利用率低；中断驱动 I/OCPU 利用率高，响应及时；DMA 效率最高，适合大数据传输；通道控制方式支持多设备并行，适用于大型系统。

### 4. Spooling 系统

- 定义：假脱机技术（Simultaneous Peripheral Operation On Line），是一种虚拟设备技术，通过内存中的输入井和输出井，将独占设备（如打印机）转化为共享设备。
- 工作原理：
  1. 输入 Spooling：用户进程的输入数据先写入输入井（内存或磁盘区域），由 Spooling 进程将数据从输入设备读入输入井，用户进程直接从输入井读取数据。
  2. 输出 Spooling：用户进程的输出数据先写入输出井，由 Spooling 进程将输出井中的数据依次写入输出设备（如打印机），用户进程无需等待设备空闲。
- 核心作用：提高独占设备利用率，实现多进程并发访问独占设备。

### 5. I/O 软件的分层结构及其功能

I/O 软件从下到上分为四层，每层提供特定功能，层间通过接口交互：

- **硬件层**：I/O 设备及控制器，执行实际的 I/O 操作（如数据传输、状态反馈）。

- **中断处理程序**：响应设备中断，保存 CPU 现场，处理设备中断请求（如通知驱动程序数据传输完成），恢复 CPU 现场。

- **设备驱动程序**：操作系统与设备的接口，将上层软件的抽象请求转化为设备的具体操作（如设置设备寄存器、发送控制命令），处理设备错误。

- 设备独立性软件：

  - 提供统一的设备接口（如 read、write 系统调用），屏蔽设备差异。
  - 实现设备分配与释放（如独占设备的申请与释放）。
  - 实现缓冲管理（如内核缓冲、双缓冲、循环缓冲），减少磁盘 I/O 次数。
  - 处理设备错误（如重试、报告错误）。
  
- **用户层 I/O 软件**：用户程序中的 I/O 函数（如 C 语言的 fopen、fread），调用系统调用接口，实现用户程序与设备的交互。

### 6. 磁盘设备读写工作原理

- 磁盘物理结构：磁盘由多个盘片组成，每个盘片有两个表面，每个表面有多个磁道，每个磁道有多个扇区（数据存储的基本单位，通常 512 字节），多个盘片的同一磁道组成柱面。
- 读写过程：
  1. 寻道：磁盘臂移动到目标磁道，消耗寻道时间（磁盘 I/O 的主要耗时）。
  2. 旋转延迟：目标扇区旋转到磁头下方，消耗旋转延迟时间（平均为磁盘旋转周期的一半）。
  3. 数据传输：磁头读取或写入扇区数据，消耗传输时间（与数据量和传输速率有关）。
- 总读写时间 = 寻道时间 + 旋转延迟 + 传输时间。

### 7. 常用磁盘臂调度算法

- **先来先服务（FCFS）**：按 I/O 请求的先后顺序调度，公平但寻道时间长，适用于轻负载。
- **最短寻道时间优先（SSTF）**：选择当前磁头位置到目标磁道距离最短的请求，减少寻道时间，但可能导致远离磁头的请求饥饿。
- **扫描算法（SCAN，电梯算法）**：磁头按一个方向（如从内到外）移动，依次处理沿途的 I/O 请求，到达磁盘边缘后反向移动（主注意已经访问的别访问了），避免饥饿，寻道效率高。
- **循环扫描算法（C-SCAN）**：磁头按一个方向移动，到达磁盘边缘后直接跳转到另一边缘的第一个磁道，不反向移动，优化扫描算法对中间磁道的偏好，适用于大容量磁盘。
- **LOOK 算法**：与 SCAN 类似，但磁头仅移动到最远的 I/O 请求磁道，无需到达磁盘边缘，进一步减少寻道时间。

